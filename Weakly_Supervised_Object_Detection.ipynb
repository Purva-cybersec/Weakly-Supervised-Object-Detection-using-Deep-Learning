{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "rm0FkZucXXo5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15AtVim1XS0B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform Images Function"
      ],
      "metadata": {
        "id": "fODLLVX0XdqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform: Resize images and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
        "    transforms.ToTensor(),         # Convert to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize for faster training\n",
        "])\n"
      ],
      "metadata": {
        "id": "EKCHsN8AXdQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading datasets"
      ],
      "metadata": {
        "id": "xLytarINRlzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, transform=transform, download=True\n",
        ")"
      ],
      "metadata": {
        "id": "vPKnW4wnRlDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e696200d-f5e6-4b7f-d5be-5fa5c034e1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 25.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, transform=transform, download=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC25SCZwP6nL",
        "outputId": "03246e82-f3b0-4763-f099-4890123a3f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the data and example classes"
      ],
      "metadata": {
        "id": "KW1gx9lLXqho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print(\"Dataset loaded. Example classes:\", train_dataset.classes)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gccb3Hu9XjXp",
        "outputId": "74565945-6f92-4676-b11f-e557cdebe04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded. Example classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a subset of the data to avoid large run-time"
      ],
      "metadata": {
        "id": "q5xYJWRdR2Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Get the CIFAR-10 dataset labels\n",
        "labels = np.array(train_dataset.targets)\n",
        "\n",
        "# Split the dataset using stratified sampling\n",
        "# Limiting to, say, 20% of the original dataset\n",
        "train_indices, _ = train_test_split(np.arange(len(train_dataset)),\n",
        "                                    test_size=0.8,  # Keep 20% of the data\n",
        "                                    stratify=labels)  # Ensure the class distribution is maintained\n",
        "\n",
        "# Create a subset of the dataset with the selected indices\n",
        "subset_train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
        "\n",
        "# Create a DataLoader for the subset of the training data\n",
        "subset_train_loader = DataLoader(subset_train_dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "EElzBlPNemlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the weakly supervised model"
      ],
      "metadata": {
        "id": "WVk81NlLXubV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "WCjEHsyOYM5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining the loss function and optimizer"
      ],
      "metadata": {
        "id": "x0oU9jV0Yxey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Actual training"
      ],
      "metadata": {
        "id": "cfH6nFrfY1Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 2: Define image transformations (resize to smaller images, normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize to smaller size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "eu3Uc7y-bv8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the model"
      ],
      "metadata": {
        "id": "-6AC6vtJSGeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load a pretrained ResNet18 model and modify it for CIFAR-10 (10 classes)\n",
        "model = models.resnet18(pretrained=True)  # Using a pretrained model\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)  # Modify final layer for CIFAR-10 classes\n",
        "model.to(device)  # Move model to device (GPU or CPU)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjKGB2ORb5XZ",
        "outputId": "8d6ec2d1-e5b1-42e5-ac9e-239f416b589f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 123MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the loss function and optimizer"
      ],
      "metadata": {
        "id": "LgondimBSJpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # For classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer"
      ],
      "metadata": {
        "id": "-Q3r_pqEb8mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "FWB-llZJSUjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch\n",
        "\n",
        "# Initialize GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training Loop\n",
        "epochs = 5  # Set number of epochs\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    for images, labels in subset_train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to device\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        # Mixed precision training\n",
        "        with autocast():  # Enable mixed precision\n",
        "            outputs = model(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Calculate loss\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()  # Backpropagation with scaled loss\n",
        "        scaler.step(optimizer)  # Update weights\n",
        "        scaler.update()  # Update the scaler\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Accuracy calculation\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Correct predictions\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Print loss and accuracy for the epoch\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(subset_train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # Optionally, save the model after each epoch\n",
        "    torch.save(model.state_dict(), f\"model_epoch_{epoch + 1}.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIWotCzdYsiK",
        "outputId": "4f55464e-b680-41f3-d0a4-41eca317302b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-3cb6a5bc7e3f>:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "<ipython-input-10-3cb6a5bc7e3f>:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Enable mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.8283, Accuracy: 72.20%\n",
            "Epoch [2/5], Loss: 0.4757, Accuracy: 84.10%\n",
            "Epoch [3/5], Loss: 0.3091, Accuracy: 89.53%\n",
            "Epoch [4/5], Loss: 0.2617, Accuracy: 91.08%\n",
            "Epoch [5/5], Loss: 0.1657, Accuracy: 94.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the model"
      ],
      "metadata": {
        "id": "yHkvnJeESbJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model state\n",
        "torch.save(model.state_dict(), 'cifar10_model.pth')\n",
        "\n",
        "# Optionally, save the optimizer state\n",
        "torch.save(optimizer.state_dict(), 'optimizer.pth')\n",
        "\n",
        "# To load the model later:\n",
        "model.load_state_dict(torch.load('cifar10_model.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMOFAiYXB__A",
        "outputId": "a514209c-94dc-4470-d2cd-bf9833856aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-824061039880>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('cifar10_model.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "9_IqRqjxSeOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    criterion = torch.nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
        "\n",
        "            # Mixed precision evaluation\n",
        "            with autocast():  # Enable mixed precision\n",
        "                outputs = model(images)  # Forward pass\n",
        "                loss = criterion(outputs, labels)  # Calculate loss\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "            total += labels.size(0)  # Total number of samples\n",
        "            correct += (predicted == labels).sum().item()  # Correct predictions\n",
        "\n",
        "    # Calculate and print the evaluation accuracy and average loss\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "UupB_QAENmsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining the test data subset"
      ],
      "metadata": {
        "id": "-KXwG9eVSlOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Define the fraction of the dataset you want to use for the subset\n",
        "subset_fraction = 0.2  # 20% of the test data\n",
        "\n",
        "# Generate random indices for the subset\n",
        "total_test_samples = len(test_dataset)\n",
        "subset_size = int(subset_fraction * total_test_samples)\n",
        "\n",
        "# Randomly sample indices without replacement\n",
        "subset_indices = np.random.choice(total_test_samples, subset_size, replace=False)\n",
        "\n",
        "# Create a Subset of the test dataset\n",
        "subset_test_dataset = Subset(test_dataset, subset_indices)\n",
        "\n",
        "# Create a DataLoader for the subset\n",
        "subset_test_loader = DataLoader(subset_test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "K0F6yWz9Qnk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, subset_test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fmJdpWCPnav",
        "outputId": "4014a181-734e-4497-ee58-a611ae9f84bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-8b81de4140f0>:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Enable mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.8753, Test Accuracy: 77.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2"
      ],
      "metadata": {
        "id": "5A_hp80gUS9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initalizing model with Dropout"
      ],
      "metadata": {
        "id": "MyX1kDtGn9pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a modified ResNet18 model with Dropout\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedResNet, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(self.model.fc.in_features, 256),  # Add intermediate FC layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout with p=0.5\n",
        "            nn.Linear(256, 10)  # Final output layer for CIFAR-10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model2 = ModifiedResNet().to(device)\n"
      ],
      "metadata": {
        "id": "yLScus6in5Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining optimizer"
      ],
      "metadata": {
        "id": "m7pC9s69oUon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer2 = optim.Adam(model2.parameters(), lr=0.001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "4I4Mkgm-oFCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model 2"
      ],
      "metadata": {
        "id": "5gv-F9aVoiY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch\n",
        "\n",
        "# Initialize GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model2.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer2.zero_grad()\n",
        "        outputs = model2(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z9fBanioTWK",
        "outputId": "77a7f31c-a86b-4cc9-bed7-ef6ea87f6211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1997f9a056b6>:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.8820, Train Accuracy: 71.63%\n",
            "Epoch [2/5], Loss: 0.6037, Train Accuracy: 81.02%\n",
            "Epoch [3/5], Loss: 0.5103, Train Accuracy: 83.90%\n",
            "Epoch [4/5], Loss: 0.4328, Train Accuracy: 86.30%\n",
            "Epoch [5/5], Loss: 0.3793, Train Accuracy: 87.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model state\n",
        "torch.save(model2.state_dict(), 'cifar10_model2.pth')\n",
        "\n",
        "# Optionally, save the optimizer state\n",
        "torch.save(optimizer.state_dict(), 'optimizer2.pth')\n",
        "\n",
        "# To load the model later:\n",
        "model2.load_state_dict(torch.load('cifar10_model2.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjqfrSzss0tA",
        "outputId": "961a8fde-35f0-4bd9-b69b-181314961289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-6a8086c7ba8a>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model2.load_state_dict(torch.load('cifar10_model2.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model 2"
      ],
      "metadata": {
        "id": "g9NjHgVxsv6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model2, test_loader, device):\n",
        "    model2.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    criterion = torch.nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
        "\n",
        "            # Mixed precision evaluation\n",
        "            with autocast():  # Enable mixed precision\n",
        "                outputs = model(images)  # Forward pass\n",
        "                loss = criterion(outputs, labels)  # Calculate loss\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "            total += labels.size(0)  # Total number of samples\n",
        "            correct += (predicted == labels).sum().item()  # Correct predictions\n",
        "\n",
        "    # Calculate and print the evaluation accuracy and average loss\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "sRb7-D3mtLvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the new model\n",
        "evaluate(model2, subset_test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fPo_i9CsyzW",
        "outputId": "4803c396-0499-487a-d883-9f52aeb47b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-e77b4e0c2127>:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Enable mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.8753, Test Accuracy: 77.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3"
      ],
      "metadata": {
        "id": "Qt7Wl9YbUXT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize model 3 with ResNet50 a bit more complex"
      ],
      "metadata": {
        "id": "dT3g1nsUu7Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedResNet50(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedResNet50, self).__init__()\n",
        "        self.model = models.resnet50(pretrained=True)\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(self.model.fc.in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Instantiate the larger model\n",
        "model3 = ModifiedResNet50().to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ajPjIifuso2",
        "outputId": "e9edf765-26b7-4fe2-a368-f1b286b886cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 179MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of Model 3 including the optimizer3"
      ],
      "metadata": {
        "id": "gHtFc3Egvf_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# Define optimizer and scheduler\n",
        "optimizer3 = optim.Adam(model3.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer3, T_max=10, eta_min=0.00001)  # Cosine annealing over 10 epochs\n",
        "\n",
        "# Training loop with scheduler\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model3.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer3.zero_grad()\n",
        "        outputs = model3(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer3.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    scheduler.step()  # Update learning rate using scheduler\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPHjjcrZvCRE",
        "outputId": "dfcd2c95-69a6-4c63-f167-e28b70ad9f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.4573, Train Accuracy: 45.67%\n",
            "Epoch [2/10], Loss: 1.0140, Train Accuracy: 65.03%\n",
            "Epoch [3/10], Loss: 0.8032, Train Accuracy: 73.09%\n",
            "Epoch [4/10], Loss: 0.6559, Train Accuracy: 78.55%\n",
            "Epoch [5/10], Loss: 0.5486, Train Accuracy: 82.00%\n",
            "Epoch [6/10], Loss: 0.4352, Train Accuracy: 85.90%\n",
            "Epoch [7/10], Loss: 0.3329, Train Accuracy: 89.15%\n",
            "Epoch [8/10], Loss: 0.2299, Train Accuracy: 92.59%\n",
            "Epoch [9/10], Loss: 0.1511, Train Accuracy: 95.17%\n",
            "Epoch [10/10], Loss: 0.1032, Train Accuracy: 96.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model state\n",
        "torch.save(model3.state_dict(), 'cifar10_model3.pth')\n",
        "\n",
        "# Optionally, save the optimizer state\n",
        "torch.save(optimizer.state_dict(), 'optimizer3.pth')\n",
        "\n",
        "# To load the model later:\n",
        "model3.load_state_dict(torch.load('cifar10_model3.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEAt-UcjwJLg",
        "outputId": "6154391e-61ba-4381-a1d5-259803244887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-656a6fb86451>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model3.load_state_dict(torch.load('cifar10_model3.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "l0pJeN_fwTd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model3, test_loader, device):\n",
        "    model3.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    criterion = torch.nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
        "\n",
        "            # Mixed precision evaluation\n",
        "            with autocast():  # Enable mixed precision\n",
        "                outputs = model(images)  # Forward pass\n",
        "                loss = criterion(outputs, labels)  # Calculate loss\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "            total += labels.size(0)  # Total number of samples\n",
        "            correct += (predicted == labels).sum().item()  # Correct predictions\n",
        "\n",
        "    # Calculate and print the evaluation accuracy and average loss\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "Qk6WNuLovkyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the new model\n",
        "evaluate(model3, subset_test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taivMUz0wXPf",
        "outputId": "34e958d4-45fd-4fb1-ecb9-b959c7e2c2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-2c510dbdb779>:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Enable mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.8753, Test Accuracy: 77.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the models"
      ],
      "metadata": {
        "id": "RXpkRcZuVKGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the saved models\n",
        "model1 = model.to(device)\n",
        "model1.load_state_dict(torch.load('/content/cifar10_model.pth'))\n",
        "\n",
        "model2 = ModifiedResNet().to(device)\n",
        "model2.load_state_dict(torch.load('/content/cifar10_model2.pth'))\n",
        "\n",
        "model3 = ModifiedResNet50().to(device)\n",
        "model3.load_state_dict(torch.load('/content/cifar10_model3.pth'))\n",
        "\n",
        "# Set all models to evaluation mode\n",
        "model1.eval()\n",
        "model2.eval()\n",
        "model3.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x02w_Mk6Pxv",
        "outputId": "5c64c45a-6419-4f04-ccf9-a4862a128150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-9132af6f033f>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model1.load_state_dict(torch.load('/content/cifar10_model.pth'))\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-37-9132af6f033f>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model2.load_state_dict(torch.load('/content/cifar10_model2.pth'))\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-37-9132af6f033f>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model3.load_state_dict(torch.load('/content/cifar10_model3.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModifiedResNet50(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (4): ReLU()\n",
              "      (5): Dropout(p=0.5, inplace=False)\n",
              "      (6): Linear(in_features=256, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Image Transformation"
      ],
      "metadata": {
        "id": "RW1_AVym6mct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (same as used during training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize to the input size of the model\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to match training\n",
        "])\n"
      ],
      "metadata": {
        "id": "MUE-eHEH6nMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load Provided Images"
      ],
      "metadata": {
        "id": "wckfN49m6otl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing test images\n",
        "image_dir = './test_images'\n",
        "image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_images(image_paths):\n",
        "    images = []\n",
        "    for path in image_paths:\n",
        "        image = Image.open(path).convert('RGB')  # Convert to RGB\n",
        "        image = transform(image)  # Apply transformations\n",
        "        images.append(image)\n",
        "    return torch.stack(images)  # Stack into a batch\n",
        "\n",
        "# Prepare batch of images\n",
        "images = load_images(image_paths).to(device)\n"
      ],
      "metadata": {
        "id": "I-vIv1Nd6rDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Images on Models"
      ],
      "metadata": {
        "id": "IqElHCQS9Sz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to get predictions\n",
        "def predict(model, images, classes):\n",
        "    outputs = model(images)  # Forward pass\n",
        "    _, predicted = torch.max(outputs, 1)  # Get class indices\n",
        "    return [classes[p] for p in predicted]  # Map indices to class names\n",
        "\n",
        "# CIFAR-10 class names\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Test all models\n",
        "print(\"Testing Model 1...\")\n",
        "predictions1 = predict(model1, images, classes)\n",
        "\n",
        "print(\"Testing Model 2...\")\n",
        "predictions2 = predict(model2, images, classes)\n",
        "\n",
        "print(\"Testing Model 3...\")\n",
        "predictions3 = predict(model3, images, classes)\n",
        "\n",
        "# Print predictions for each image\n",
        "for idx, img_path in enumerate(image_paths):\n",
        "    print(f\"\\nImage: {os.path.basename(img_path)}\")\n",
        "    print(f\"Model 1 Prediction: {predictions1[idx]}\")\n",
        "    print(f\"Model 2 Prediction: {predictions2[idx]}\")\n",
        "    print(f\"Model 3 Prediction: {predictions3[idx]}\")\n"
      ],
      "metadata": {
        "id": "CywhqwEx9T1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cae578-e349-4735-e60a-348070dfb8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Model 1...\n",
            "Testing Model 2...\n",
            "Testing Model 3...\n",
            "\n",
            "Image: img3.jpg\n",
            "Model 1 Prediction: frog\n",
            "Model 2 Prediction: bird\n",
            "Model 3 Prediction: automobile\n",
            "\n",
            "Image: img1.jpg\n",
            "Model 1 Prediction: airplane\n",
            "Model 2 Prediction: airplane\n",
            "Model 3 Prediction: automobile\n",
            "\n",
            "Image: img5.jpg\n",
            "Model 1 Prediction: truck\n",
            "Model 2 Prediction: truck\n",
            "Model 3 Prediction: automobile\n",
            "\n",
            "Image: img2.jpg\n",
            "Model 1 Prediction: truck\n",
            "Model 2 Prediction: automobile\n",
            "Model 3 Prediction: automobile\n",
            "\n",
            "Image: img4.jpg\n",
            "Model 1 Prediction: dog\n",
            "Model 2 Prediction: dog\n",
            "Model 3 Prediction: automobile\n"
          ]
        }
      ]
    }
  ]
}